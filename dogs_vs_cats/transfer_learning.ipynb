{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 猫狗大战（Dogs vs Cats）\n",
    "\n",
    "## 项目介绍\n",
    "\n",
    "**TODO：介绍Dogs vs Cats 项目的背景**\n",
    "\n",
    "## 项目内容\n",
    "\n",
    "* [Step0](#step0): 导入数据集\n",
    "* [Step1](#step1): 数据分析\n",
    "* [Step2](#step2): 模型预测\n",
    "* [Step3](#step3): 结果分析\n",
    " \n",
    "<a id=\"step0\"></a>\n",
    "## 1. 导入数据集\n",
    "\n",
    "读取datas目录下的数据集，并分为train和test两类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "data = load_files('datas')\n",
    "\n",
    "files = np.array(data['filenames'])\n",
    "targets = np.array(data['target'])\n",
    "target_names = np.array(data['target_names'])\n",
    "\n",
    "train_files = [files[idx] for idx in range(len(files)) if targets[idx] == np.argwhere(target_names == 'train')]\n",
    "test_files = [files[idx] for idx in range(len(files)) if targets[idx] == np.argwhere(target_names == 'test')]\n",
    "\n",
    "def getFileName(elem):\n",
    "    _,file = os.path.split(elem)\n",
    "    name,_ = os.path.splitext(file)\n",
    "    return int(name)\n",
    "test_files.sort(key=getFileName)\n",
    "\n",
    "print(\"There are {} train images.\".format(len(train_files)))\n",
    "print(\"There are {} test images.\".format(len(test_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "可视化训练数据集中前12张图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize_img(img_path, ax):\n",
    "    img = cv2.imread(img_path)\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "for i in range(32):\n",
    "    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n",
    "    visualize_img(train_files[i], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"step1\"></a>\n",
    "## 2. 数据分析\n",
    "\n",
    "### 2.1 提取数据特征\n",
    "\n",
    "通过查看训练数据集，发现数据集的标注信息是定义在文件名的，从文件名中提取对应的数据特征，如下表：\n",
    "\n",
    "|文件|标注（cat）|标注（dog）|\n",
    "|-|-|-|\n",
    "|datas/train/cat.6938.jpg  |1|0|\n",
    "|datas/train/dog.11432.jpg |0|1|\n",
    "|datas/train/cat.433.jpg   |1|0|\n",
    "|datas/train/cat.11305.jpg |1|0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_labels = (\"cat\", \"dog\")\n",
    "\n",
    "train_labels = []\n",
    "for file in train_files:\n",
    "    for idx in range(len(data_labels)):\n",
    "        if data_labels[idx] in file:\n",
    "            train_labels.append(idx)\n",
    "\n",
    "train_targets = np_utils.to_categorical(np.array(train_labels), 2)\n",
    "print(\"The first 5 train file:\\n{}\\n\".format(train_files[0:5]))\n",
    "print(\"The first 5 train targets:\\n{}\\n\".format(train_targets[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.2 数据处理\n",
    "\n",
    "根据文件名，读取图片文件中的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # 用PIL加载RGB图像为PIL.Image.Image类型\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # 将PIL.Image.Image类型转化为格式为(224, 224, 3)的3维张量\n",
    "    x = image.img_to_array(img)\n",
    "    # 将3维张量转化为格式为(1, 224, 224, 3)的4维张量并返回\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# 加载图片资源\n",
    "train_tensors = paths_to_tensor(train_files)\n",
    "test_tensors = paths_to_tensor(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.2 验证集划分\n",
    "\n",
    "从sklearn.model_selection中导入train_test_split\n",
    "将train_files和train_targets作为train_test_split的输入变量\n",
    "设置test_size为0.2，划分出20%的验证集，80%的数据留作新的训练集。\n",
    "设置random_state随机种子，以确保每一次运行都可以得到相同划分的结果。（随机种子固定，生成的随机序列就是确定的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = train_test_split(train_tensors, train_targets, test_size=0.2, random_state=100)\n",
    "\n",
    "print(\"Splited train set num: {}\".format(len(X_train)))\n",
    "print(\"Splited valid set num: {}\".format(len(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"step2\"></a>\n",
    "## 3. 模型预测\n",
    "\n",
    "基于[Deep Residual Networks](https://github.com/KaimingHe/deep-residual-networks#models) 来创建CNN模型。\n",
    "\n",
    "**TODO: 介绍为什么使用ResNet-50，以及ResNet模型的原理**\n",
    "\n",
    "### 3.1 构建模型\n",
    "\n",
    "为了提高模型的训练速度和质量，这里使用迁移学习，主要构建全连接层模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GlobalAveragePooling2D(input_shape=(1, 1, 2048)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.2 训练模型\n",
    "\n",
    "使用构建好的ResNet50模型进行训练，并将训练的权重保存到hdf5文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 加载已生成的bottleneck features\n",
    "bottleneck_features = np.load('bottlenecks_resnet50.npz')\n",
    "train_bottleneck = bottleneck_features['train']\n",
    "valid_bottleneck = bottleneck_features['valid']\n",
    "test_bottleneck = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 训练全连接层网络模型\n",
    "checkpointer = ModelCheckpoint(filepath='weights_best_resnet50.hdf5', verbose=1, save_best_only=True)\n",
    "history = model.fit(train_bottleneck, y_train, validation_data=(valid_bottleneck, y_valid),\n",
    "        epochs=30, batch_size=32, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "将模型的训练过程进行可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.3 验证模型\n",
    "\n",
    "根据测试集中的数据进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load trained model weights\n",
    "model.load_weights('weights_best_resnet50.hdf5')\n",
    "\n",
    "# Predict test set\n",
    "test_predict = [np.argmax(model.predict(np.expand_dims(feature, axis=0))) for feature in test_bottleneck]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "将部分预测的结果进行可视化预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot a random sample of test images, their predicted labels\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "for i, idx in enumerate(np.random.choice(test_tensors.shape[0], size=32, replace=False)):\n",
    "    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n",
    "    visualize_img(test_files[idx], ax)\n",
    "    pred_idx = test_predict[idx]\n",
    "    ax.set_title(\"{}\".format(data_labels[pred_idx]), color=(\"green\") if pred_idx > 0 else (\"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "将预测的结果提交到kaggle，以便得到模型的准确率排名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## 加载结果格式\n",
    "submit_frame = pd.read_csv(\"sample_submission.csv\")\n",
    "## 保存结果\n",
    "submit_frame['label'] = test_predict\n",
    "test_result_name = \"submission.csv\"\n",
    "submit_frame[['id','label']].to_csv(test_result_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"step3\"></a>\n",
    "## 4. 结果分析\n",
    "\n",
    "### 4.1 测试模型\n",
    "\n",
    "**TODO: 分析算法的不足，提供优化建议，并提供参数优化后的结果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights('saved_models/weights.best.Resnet50.hdf5')\n",
    "\n",
    "# Resnet50_predict = [np.argmax(model.predict(np.expand_dims(feature, axis=0))) for feature in test_Resnet50]\n",
    "\n",
    "# print(\"The first 5 train targets:\\n{}\\n\".format(train_targets[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4.2 提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ## 加载结果格式\n",
    "# submit_frame = pd.read_csv(\"sample_submission.csv\")\n",
    "# ## 保存结果\n",
    "# result = pd.merge(submit_frame, test_content, on=\"id\", how='left')\n",
    "# result = result.rename(index=str, columns={\"cuisine_y\": \"cuisine\"})\n",
    "# test_result_name = \"tfidf_cuisine_test.csv\"\n",
    "# result[['id','cuisine']].to_csv(test_result_name,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
