{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 猫狗大战（Dogs vs Cats）\n",
    "\n",
    "## 项目介绍\n",
    "\n",
    "**TODO：介绍Dogs vs Cats 项目的背景**\n",
    "\n",
    "## 项目内容\n",
    "\n",
    "* [Step0](#step0): 导入数据集\n",
    "* [Step1](#step1): 数据分析\n",
    "* [Step2](#step2): 模型预测\n",
    "* [Step3](#step3): 结果分析\n",
    " \n",
    "<a id=\"step0\"></a>\n",
    "## 1. 导入数据集\n",
    "\n",
    "读取datas目录下的数据集，并分为train和test两类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "data = load_files('datas')\n",
    "\n",
    "files = np.array(data['filenames'])\n",
    "targets = np.array(data['target'])\n",
    "target_names = np.array(data['target_names'])\n",
    "\n",
    "test_files = [files[idx] for idx in range(len(files)) if targets[idx] == np.argwhere(target_names == 'test')]\n",
    "\n",
    "def getFileName(elem):\n",
    "    _,file = os.path.split(elem)\n",
    "    name,_ = os.path.splitext(file)\n",
    "    return int(name)\n",
    "test_files.sort(key=getFileName)\n",
    "\n",
    "print(\"There are {} test images.\".format(len(test_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step2\"></a>\n",
    "## 3. 模型预测\n",
    "\n",
    "基于[Deep Residual Networks](https://github.com/KaimingHe/deep-residual-networks#models) 来创建CNN模型。\n",
    "\n",
    "**TODO: 介绍为什么使用ResNet-50，以及ResNet模型的原理**\n",
    "\n",
    "### 3.1 构建模型\n",
    "\n",
    "为了提高模型的训练速度和质量，这里使用迁移学习，主要构建全连接层模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GlobalAveragePooling2D(input_shape=(1, 1, 2048)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 训练模型\n",
    "\n",
    "使用构建好的ResNet50模型进行训练，并将训练的权重保存到hdf5文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载已生成的bottleneck features\n",
    "bottleneck_features = np.load('bottlenecks_resnet50.npz')\n",
    "X_train = bottleneck_features['X_train']\n",
    "y_train = bottleneck_features['y_train']\n",
    "X_valid = bottleneck_features['X_valid']\n",
    "y_valid = bottleneck_features['y_valid']\n",
    "X_test = bottleneck_features['X_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 训练全连接层网络模型\n",
    "checkpointer = ModelCheckpoint(filepath='weights_best_resnet50.hdf5', verbose=1, save_best_only=True)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        epochs=30, batch_size=32, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将模型的训练过程进行可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 验证模型\n",
    "\n",
    "根据测试集中的数据进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load trained model weights\n",
    "model.load_weights('weights_best_resnet50.hdf5')\n",
    "\n",
    "# Predict test set\n",
    "y_test = [model.predict(np.expand_dims(feature, axis=0)) for feature in X_test]\n",
    "test_pred = [np.argmax(y) for y in y_test]\n",
    "test_result = [y[0][0] for y in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将部分预测的结果进行可视化预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize_img(img_path, ax):\n",
    "    img = cv2.imread(img_path)\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# plot a random sample of test images, their predicted labels\n",
    "data_labels = (\"cat\", \"dog\")\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "for i, idx in enumerate(np.random.choice(test_tensors.shape[0], size=32, replace=False)):\n",
    "    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n",
    "    visualize_img(test_files[idx], ax)\n",
    "    pred_idx = test_pred[idx]\n",
    "    ax.set_title(\"{}\".format(data_labels[pred_idx]), color=(\"green\") if pred_idx > 0 else (\"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将预测的结果提交到kaggle，以便得到模型的准确率排名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## 加载结果格式\n",
    "submit_frame = pd.read_csv(\"sample_submission.csv\")\n",
    "## 保存结果\n",
    "submit_frame['label'] = test_result\n",
    "result_name = \"submission.csv\"\n",
    "submit_frame[['id','label']].to_csv(result_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step3\"></a>\n",
    "## 4. 结果分析\n",
    "\n",
    "### 4.1 测试模型\n",
    "\n",
    "**TODO: 分析算法的不足，提供优化建议，并提供参数优化后的结果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights('saved_models/weights.best.Resnet50.hdf5')\n",
    "\n",
    "# Resnet50_predict = [np.argmax(model.predict(np.expand_dims(feature, axis=0))) for feature in test_Resnet50]\n",
    "\n",
    "# print(\"The first 5 train targets:\\n{}\\n\".format(train_targets[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## 加载结果格式\n",
    "# submit_frame = pd.read_csv(\"sample_submission.csv\")\n",
    "# ## 保存结果\n",
    "# result = pd.merge(submit_frame, test_content, on=\"id\", how='left')\n",
    "# result = result.rename(index=str, columns={\"cuisine_y\": \"cuisine\"})\n",
    "# test_result_name = \"tfidf_cuisine_test.csv\"\n",
    "# result[['id','cuisine']].to_csv(test_result_name,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
