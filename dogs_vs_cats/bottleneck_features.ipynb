{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 猫狗大战（Dogs vs Cats）\n",
    "\n",
    "## 项目介绍\n",
    "\n",
    "使用要迁移学习的模型，将数据集中的bottleneck特征提取出来，方便后续训练新模型。\n",
    " \n",
    "\n",
    "## 1. 导入数据集\n",
    "\n",
    "将下载的数据集压缩包解压到指定到文件夹中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Unzip all zip file to the path.\n",
    "def UnzipFile(filename, datapath):\n",
    "    # Check filename\n",
    "    if filename.strip() == \"\":\n",
    "        print(\"filename should not be null string!\")\n",
    "        return False\n",
    "\n",
    "    # Check datapath\n",
    "    if datapath.strip() == \"\":\n",
    "        print(\"datapath should not be null string!\")\n",
    "        return False\n",
    "    \n",
    "    # Check file exist\n",
    "    if not os.path.exists(filename):\n",
    "        print(\"{} not found!\".format(filename))\n",
    "        return False\n",
    "\n",
    "    # Check filename's extension\n",
    "    if os.path.splitext(filename)[1] != '.zip':\n",
    "        print(\"{} should be with '*.zip' ext!\".format(filename))\n",
    "        return False\n",
    "\n",
    "    # Unzip the file\n",
    "    file_zip = zipfile.ZipFile(filename, 'r')\n",
    "    for file in file_zip.namelist():\n",
    "        file_zip.extract(file, datapath)\n",
    "        sub_filename = os.path.join(datapath, file)\n",
    "\n",
    "        if os.path.splitext(sub_filename)[1] != '.zip':\n",
    "            continue\n",
    "\n",
    "        UnzipFile(sub_filename, datapath)\n",
    "\n",
    "    file_zip.close()\n",
    "    os.remove(filename)\n",
    "    print(\"unzip {} successfully!\".format(filename))\n",
    "\n",
    "    return True        \n",
    "\n",
    "if not os.path.exists(\"datas/\"):\n",
    "    UnzipFile(\"train.zip\", \"datas/\")\n",
    "    UnzipFile(\"test.zip\", \"datas/\") \n",
    "else:\n",
    "    print(\"datas is ok!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "读取datas目录下的数据集，并分为train和test两类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "data = load_files('datas')\n",
    "\n",
    "files = np.array(data['filenames'])\n",
    "targets = np.array(data['target'])\n",
    "target_names = np.array(data['target_names'])\n",
    "\n",
    "train_files = [files[idx] for idx in range(len(files)) if targets[idx] == np.argwhere(target_names == 'train')]\n",
    "test_files = [files[idx] for idx in range(len(files)) if targets[idx] == np.argwhere(target_names == 'test')]\n",
    "\n",
    "def getFileName(elem):\n",
    "    _,file = os.path.split(elem)\n",
    "    name,_ = os.path.splitext(file)\n",
    "    return int(name)\n",
    "test_files.sort(key=getFileName)\n",
    "\n",
    "print(\"There are {} train images.\".format(len(train_files)))\n",
    "print(\"There are {} test images.\".format(len(test_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "可视化训练数据集中前12张图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize_img(img_path, ax):\n",
    "    img = cv2.imread(img_path)\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "for i in range(32):\n",
    "    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n",
    "    visualize_img(train_files[i], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"step1\"></a>\n",
    "## 2. 数据分析\n",
    "\n",
    "### 2.1 提取数据特征\n",
    "\n",
    "通过查看训练数据集，发现数据集的标注信息是定义在文件名的，从文件名中提取对应的数据特征，如下表：\n",
    "\n",
    "|文件|标注（cat=0.0,dog=1.0）|\n",
    "|-|-|\n",
    "|datas/train/cat.6938.jpg  |0.0|\n",
    "|datas/train/dog.11432.jpg |1.0|\n",
    "|datas/train/cat.433.jpg   |0.0|\n",
    "|datas/train/cat.11305.jpg |0.0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_labels = (\"cat\", \"dog\")\n",
    "\n",
    "train_targets = []\n",
    "for file in train_files:\n",
    "    for idx in range(len(data_labels)):\n",
    "        if data_labels[idx] in file:\n",
    "            train_targets.append(float(idx))\n",
    "\n",
    "print(\"The first 5 train file:\\n{}\\n\".format(train_files[0:5]))\n",
    "print(\"The first 5 train targets:\\n{}\\n\".format(train_targets[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析图片的分辨率的散点分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def img_shapes(files):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for file in files:\n",
    "        img = cv2.imread(file)\n",
    "        X.append(img.shape[0])\n",
    "        Y.append(img.shape[1])\n",
    "    return X,Y\n",
    "\n",
    "# 提取训练集图片分辨率信息\n",
    "train_X, train_Y = img_shapes(train_files)\n",
    "test_X, test_Y = img_shapes(test_files)\n",
    "\n",
    "# 散点图可视化图片的分辨率分布情况\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "p1 = ax.scatter(train_X,train_Y, color='b')\n",
    "p2 = ax.scatter(test_X,test_Y, color='r')\n",
    "ax.legend((p1, p2), ('train', 'test'), loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "筛选分辨率异常的数据（分辨率宽或高都大于600），并从中剔除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 筛选分辨率异常的数据\n",
    "ids = []\n",
    "for i in range(len(train_files)):\n",
    "    if train_X[i] > 600 or train_Y[i] > 600:\n",
    "        ids.append(i)\n",
    "print(\"There are {} images with invalid shape!\".format(len(ids)))\n",
    "\n",
    "# 从训练集中删除分辨率异常的数据\n",
    "for i in range(len(ids)):\n",
    "    del train_files[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.2 数据处理\n",
    "\n",
    "根据文件名，读取图片文件中的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # 用PIL加载RGB图像为PIL.Image.Image类型\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # 将PIL.Image.Image类型转化为格式为(224, 224, 3)的3维张量\n",
    "    x = image.img_to_array(img)\n",
    "    # 将3维张量转化为格式为(1, 224, 224, 3)的4维张量并返回\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# 加载图片资源\n",
    "train_tensors = paths_to_tensor(train_files)\n",
    "test_tensors = paths_to_tensor(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 数据清洗\n",
    "\n",
    "由于我们无法保证数据的正确性，需要通过数据清洗进行排查。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ImageNet中所有狗的分类\n",
    "dogs = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "# ImageNet中所有猫的分类\n",
    "cats=[\n",
    "'n02123045','n02123159','n02123394','n02123597'\n",
    ",'n02124075','n02125311','n02127052']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用ImageNet数据集预训练的Resnet50来预测训练集数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "# 使用经过imagenet训练的无全连接层ResNet50模型\n",
    "prepross_model = ResNet50(weights='imagenet')\n",
    "\n",
    "# 使用imagenet预测train数据集的分类\n",
    "pred_targets = decode_predictions(prepross_model.predict(preprocess_input(train_tensors), verbose=1), top=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据预测结果，从训练集中筛选出非猫非狗的数据，并清理掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 从训练集中筛选非猫非狗的数据\n",
    "ids = []\n",
    "for idx in range(len(pred_targets)):\n",
    "    for pred in pred_targets[idx]:\n",
    "        if pred[0] not in dogs:\n",
    "            if pred[0] not in cats:\n",
    "                ids.append(idx)\n",
    "print(\"Find {} invalid train datas.\".format(len(ids)))\n",
    "\n",
    "# 可视化所有非猫非狗的训练集数据\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "for i in range(len(ids)):\n",
    "    ax = fig.add_subplot(len(ids)/8 + 1, 8, i + 1, xticks=[], yticks=[])\n",
    "    visualize_img(train_files[ids[i]], ax)\n",
    "    \n",
    "# 从训练集中删除非猫非狗的数据\n",
    "for i in ids:\n",
    "    del train_tensors[i]\n",
    "print(\"There are {} train images now!\".format(len(train_tensors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.4 验证集划分\n",
    "\n",
    "从sklearn.model_selection中导入train_test_split\n",
    "将train_files和train_targets作为train_test_split的输入变量\n",
    "设置test_size为0.2，划分出20%的验证集，80%的数据留作新的训练集。\n",
    "设置random_state随机种子，以确保每一次运行都可以得到相同划分的结果。（随机种子固定，生成的随机序列就是确定的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = train_test_split(train_tensors, train_targets, test_size=0.2, random_state=100)\n",
    "\n",
    "print(\"Splited train set num: {}\".format(len(X_train)))\n",
    "print(\"Splited valid set num: {}\".format(len(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"step2\"></a>\n",
    "## 3. 迁移学习\n",
    "\n",
    "\n",
    "### 3.1 迁移无全连接层的模型\n",
    "\n",
    "为了提高模型的训练速度和质量，这里使用迁移学习。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# 使用经过imagenet训练的无全连接层ResNet50模型\n",
    "resnet_model = ResNet50(include_top=False, weights='imagenet')\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2 提取数据集的特征数据\n",
    "\n",
    "使用迁移的模型分别提取无全连接层的训练集、验证集和测试集的数据特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# 提取训练集特征\n",
    "train_input = preprocess_input(X_train)\n",
    "train_feature = resnet_model.predict(train_input, verbose=1)\n",
    "print(train_feature.shape)\n",
    "\n",
    "# 提取验证集特征\n",
    "valid_input = preprocess_input(X_valid)\n",
    "valid_feature = resnet_model.predict(valid_input, verbose=1)\n",
    "print(valid_feature.shape)\n",
    "\n",
    "# 提取测试集特征\n",
    "test_input = preprocess_input(test_tensors)\n",
    "test_feature = resnet_model.predict(test_input, verbose=1)\n",
    "print(test_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.3 保存特征数据\n",
    "\n",
    "将上述提取的特征数据保存到文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 将特征数据保存到bottlenecks\n",
    "np.savez('bottlenecks_resnet50.npz', \n",
    "         X_train=train_feature, y_train=y_train, \n",
    "         X_valid=valid_feature, y_valid=y_valid, \n",
    "         X_test=test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
