{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 猫狗大战（Dogs vs Cats）\n",
    "\n",
    "## 项目介绍\n",
    "\n",
    "使用要迁移学习的模型，将数据集中的bottleneck特征提取出来，方便后续训练新模型。\n",
    " \n",
    "\n",
    "## 1. 导入数据集\n",
    "\n",
    "将下载的数据集压缩包进行解压，已经数据文件的按类别分类等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Unzip all zip file to the path.\n",
    "def UnzipFile(filename, datapath):\n",
    "    # Check filename\n",
    "    if filename.strip() == \"\":\n",
    "        print(\"filename should not be null string!\")\n",
    "        return False\n",
    "\n",
    "    # Check datapath\n",
    "    if datapath.strip() == \"\":\n",
    "        print(\"{} should not be null string!\".format(datapath))\n",
    "        return False\n",
    "\n",
    "    # Check filename's extension\n",
    "    if os.path.splitext(filename)[1] != '.zip':\n",
    "        print(\"{} should be with '*.zip' ext!\".format(filename))\n",
    "        return False\n",
    "\n",
    "    # Unzip the file\n",
    "    file_zip = zipfile.ZipFile(filename, 'r')\n",
    "    for file in file_zip.namelist():\n",
    "        file_zip.extract(file, datapath)\n",
    "        sub_filename = os.path.join(datapath, file)\n",
    "        print(sub_filename)\n",
    "\n",
    "        if os.path.splitext(sub_filename)[1] != '.zip':\n",
    "            continue\n",
    "\n",
    "        UnzipFile(sub_filename, datapath)\n",
    "\n",
    "    file_zip.close()\n",
    "    os.remove(filename) \n",
    "\n",
    "    return True\n",
    "\n",
    "# Format the data files for trainning models.\n",
    "def FormatDatas(datapath):\n",
    "    train_list = os.listdir(datapath + \"/train\")\n",
    "    train_dog = list(filter(lambda x:x[:3] == \"dog\", train_list))\n",
    "    os.makedirs(datapath + \"/train/dog\")\n",
    "    for file in train_dog:\n",
    "        shutil.move(datapath + \"/train/\" + file, datapath + \"/train/dog/\" + file)\n",
    "\n",
    "    train_cat = list(filter(lambda x:x[:3] == \"cat\", train_list))\n",
    "    os.makedirs(datapath + \"/train/cat\")\n",
    "    for file in train_cat:\n",
    "        shutil.move(datapath + \"/train/\" + file, datapath + \"/train/cat/\" + file)\n",
    "        \n",
    "\n",
    "if not os.path.exists(\"datas/\"):\n",
    "    UnzipFile(\"train.zip\", \"datas/\")\n",
    "    UnzipFile(\"test.zip\", \"datas/\")\n",
    "    FormatDatas(\"datas/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取datas目录下的数据集，并分为train和test两类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "data = load_files('datas')\n",
    "\n",
    "files = np.array(data['filenames'])\n",
    "targets = np.array(data['target'])\n",
    "target_names = np.array(data['target_names'])\n",
    "\n",
    "train_files = [files[idx] for idx in range(len(files)) if targets[idx] == np.argwhere(target_names == 'train')]\n",
    "test_files = [files[idx] for idx in range(len(files)) if targets[idx] == np.argwhere(target_names == 'test')]\n",
    "\n",
    "def getFileName(elem):\n",
    "    _,file = os.path.split(elem)\n",
    "    name,_ = os.path.splitext(file)\n",
    "    return int(name)\n",
    "test_files.sort(key=getFileName)\n",
    "\n",
    "print(\"There are {} train images.\".format(len(train_files)))\n",
    "print(\"There are {} test images.\".format(len(test_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"step1\"></a>\n",
    "## 2. 数据分析\n",
    "\n",
    "### 2.1 提取数据特征\n",
    "\n",
    "通过查看训练数据集，发现数据集的标注信息是定义在文件名的，从文件名中提取对应的数据特征，如下表：\n",
    "\n",
    "|文件|标注（cat）|标注（dog）|\n",
    "|-|-|-|\n",
    "|datas/train/cat.6938.jpg  |1|0|\n",
    "|datas/train/dog.11432.jpg |0|1|\n",
    "|datas/train/cat.433.jpg   |1|0|\n",
    "|datas/train/cat.11305.jpg |1|0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_labels = (\"cat\", \"dog\")\n",
    "\n",
    "train_labels = []\n",
    "for file in train_files:\n",
    "    for idx in range(len(data_labels)):\n",
    "        if data_labels[idx] in file:\n",
    "            train_labels.append(idx)\n",
    "\n",
    "train_targets = np_utils.to_categorical(np.array(train_labels), 2)\n",
    "print(\"The first 5 train file:\\n{}\\n\".format(train_files[0:5]))\n",
    "print(\"The first 5 train targets:\\n{}\\n\".format(train_targets[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.2 数据处理\n",
    "\n",
    "根据文件名，读取图片文件中的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # 用PIL加载RGB图像为PIL.Image.Image类型\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # 将PIL.Image.Image类型转化为格式为(224, 224, 3)的3维张量\n",
    "    x = image.img_to_array(img)\n",
    "    # 将3维张量转化为格式为(1, 224, 224, 3)的4维张量并返回\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# 加载图片资源\n",
    "train_tensors = paths_to_tensor(train_files)\n",
    "test_tensors = paths_to_tensor(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.2 验证集划分\n",
    "\n",
    "从sklearn.model_selection中导入train_test_split\n",
    "将train_files和train_targets作为train_test_split的输入变量\n",
    "设置test_size为0.2，划分出20%的验证集，80%的数据留作新的训练集。\n",
    "设置random_state随机种子，以确保每一次运行都可以得到相同划分的结果。（随机种子固定，生成的随机序列就是确定的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = train_test_split(train_tensors, train_targets, test_size=0.2, random_state=100)\n",
    "\n",
    "print(\"Splited train set num: {}\".format(len(X_train)))\n",
    "print(\"Splited valid set num: {}\".format(len(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"step2\"></a>\n",
    "## 3. 迁移学习\n",
    "\n",
    "基于[Deep Residual Networks](https://github.com/KaimingHe/deep-residual-networks#models) 来创建CNN模型。\n",
    "\n",
    "**TODO: 介绍为什么使用ResNet-50，以及ResNet模型的原理**\n",
    "\n",
    "### 3.1 迁移无全连接层的模型\n",
    "\n",
    "为了提高模型的训练速度和质量，这里使用迁移学习。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# 使用经过imagenet训练的无全连接层ResNet50模型\n",
    "resnet_model = ResNet50(include_top=False, weights='imagenet')\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2 提取数据集的特征数据\n",
    "\n",
    "使用迁移的模型分别提取无全连接层的训练集、验证集和测试集的数据特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "# 提取训练集特征\n",
    "train_input = preprocess_input(X_train)\n",
    "train_feature = resnet_model.predict(train_input, verbose=1)\n",
    "print(train_feature.shape)\n",
    "\n",
    "# 提取验证集特征\n",
    "valid_input = preprocess_input(X_valid)\n",
    "valid_feature = resnet_model.predict(valid_input, verbose=1)\n",
    "print(valid_feature.shape)\n",
    "\n",
    "# 提取测试集特征\n",
    "test_input = preprocess_input(test_tensors)\n",
    "test_feature = resnet_model.predict(test_input, verbose=1)\n",
    "print(test_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.3 保存特征数据\n",
    "\n",
    "将上述提取的特征数据保存到文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 将特征数据保存到bottlenecks\n",
    "np.savez('bottlenecks_resnet50.npz', train=train_feature, valid=valid_feature, test=test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
